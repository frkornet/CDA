{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import gc; gc.collect()\n",
    "\n",
    "from   pathlib  import Path\n",
    "from time                    import time\n",
    "\n",
    "from scipy.signal            import argrelmin, argrelmax\n",
    "\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from category_encoders       import WOEEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline        import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing   import KBinsDiscretizer, FunctionTransformer, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute          import SimpleImputer\n",
    "\n",
    "from symbols                import BUY_THRESHOLD\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "YFLOAD_PATH = '/Users/frkornet/CDA/Project/stockie/data/yfin/'\n",
    "TRADE_PERIOD    = \"10y\"\n",
    "NAME_MAP        = f'/Users/frkornet/CDA/Project/fund_indicators/name_map.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_n_smooth(ticker, period):\n",
    "    \"\"\"\n",
    "    Copy of what is in util.py. Except this version reads what has been read \n",
    "    from yfinance and stored on file. The stored version is smoothed already, \n",
    "    and reading from disk should be much faster as it avoids the expensive \n",
    "    smoothing operation. The reading from file, will only return success if \n",
    "    there is at least 5 years worth of data to work with. \n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    try:\n",
    "       hist = pd.read_csv(f'{YFLOAD_PATH}{ticker}.csv')\n",
    "       hist.index = hist.Date.values\n",
    "       del hist['Date']\n",
    "       success = len(hist) > 5 * 252\n",
    "       print(f'Successfully retrieved smoothed price data for {ticker} '+\n",
    "             f'(len(hist)={len(hist)}, success={success})')\n",
    "    except:\n",
    "       hist = None\n",
    "       success = False\n",
    "       print(f'Failed to find {ticker}.csv in {YFLOAD_PATH}!')\n",
    "    \n",
    "    return success, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved smoothed price data for AFG (len(hist)=2517, success=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>smooth</th>\n",
       "      <th>P/E Ratio</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-02-14</th>\n",
       "      <td>24.07</td>\n",
       "      <td>24.07</td>\n",
       "      <td>23.82</td>\n",
       "      <td>23.87</td>\n",
       "      <td>335600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.960931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-15</th>\n",
       "      <td>23.83</td>\n",
       "      <td>23.99</td>\n",
       "      <td>23.77</td>\n",
       "      <td>23.93</td>\n",
       "      <td>389600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.967712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-16</th>\n",
       "      <td>23.95</td>\n",
       "      <td>24.14</td>\n",
       "      <td>23.95</td>\n",
       "      <td>24.06</td>\n",
       "      <td>242100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.974493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-17</th>\n",
       "      <td>24.02</td>\n",
       "      <td>24.34</td>\n",
       "      <td>23.98</td>\n",
       "      <td>24.33</td>\n",
       "      <td>190400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.981275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-18</th>\n",
       "      <td>24.36</td>\n",
       "      <td>24.49</td>\n",
       "      <td>24.23</td>\n",
       "      <td>24.48</td>\n",
       "      <td>226900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.988056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-08</th>\n",
       "      <td>100.52</td>\n",
       "      <td>103.36</td>\n",
       "      <td>100.51</td>\n",
       "      <td>103.04</td>\n",
       "      <td>863800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.591670</td>\n",
       "      <td>36.931900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-09</th>\n",
       "      <td>102.83</td>\n",
       "      <td>105.09</td>\n",
       "      <td>102.25</td>\n",
       "      <td>104.34</td>\n",
       "      <td>498400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.205907</td>\n",
       "      <td>37.397849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-10</th>\n",
       "      <td>104.89</td>\n",
       "      <td>107.42</td>\n",
       "      <td>103.97</td>\n",
       "      <td>106.44</td>\n",
       "      <td>961700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.820145</td>\n",
       "      <td>38.150538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-11</th>\n",
       "      <td>106.16</td>\n",
       "      <td>108.30</td>\n",
       "      <td>106.00</td>\n",
       "      <td>108.03</td>\n",
       "      <td>521700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.434382</td>\n",
       "      <td>38.720430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-12</th>\n",
       "      <td>108.00</td>\n",
       "      <td>108.74</td>\n",
       "      <td>107.56</td>\n",
       "      <td>108.04</td>\n",
       "      <td>582700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>101.048619</td>\n",
       "      <td>38.724014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2517 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close  Volume  Dividends  Stock Splits  \\\n",
       "2011-02-14   24.07   24.07   23.82   23.87  335600        0.0             0   \n",
       "2011-02-15   23.83   23.99   23.77   23.93  389600        0.0             0   \n",
       "2011-02-16   23.95   24.14   23.95   24.06  242100        0.0             0   \n",
       "2011-02-17   24.02   24.34   23.98   24.33  190400        0.0             0   \n",
       "2011-02-18   24.36   24.49   24.23   24.48  226900        0.0             0   \n",
       "...            ...     ...     ...     ...     ...        ...           ...   \n",
       "2021-02-08  100.52  103.36  100.51  103.04  863800        0.0             0   \n",
       "2021-02-09  102.83  105.09  102.25  104.34  498400        0.0             0   \n",
       "2021-02-10  104.89  107.42  103.97  106.44  961700        0.0             0   \n",
       "2021-02-11  106.16  108.30  106.00  108.03  521700        0.0             0   \n",
       "2021-02-12  108.00  108.74  107.56  108.04  582700        0.0             0   \n",
       "\n",
       "                smooth  P/E Ratio  target  \n",
       "2011-02-14   23.960931        NaN       0  \n",
       "2011-02-15   23.967712        NaN       0  \n",
       "2011-02-16   23.974493        NaN       0  \n",
       "2011-02-17   23.981275        NaN       0  \n",
       "2011-02-18   23.988056        NaN       0  \n",
       "...                ...        ...     ...  \n",
       "2021-02-08   98.591670  36.931900       0  \n",
       "2021-02-09   99.205907  37.397849       0  \n",
       "2021-02-10   99.820145  38.150538       0  \n",
       "2021-02-11  100.434382  38.720430       0  \n",
       "2021-02-12  101.048619  38.724014       0  \n",
       "\n",
       "[2517 rows x 10 columns]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = 'AFG'\n",
    "target = 'target'\n",
    "success, hist = get_stock_n_smooth(ticker, TRADE_PERIOD)\n",
    "assert success == True, \"Unable to get historical price data and smooth price!\"\n",
    "hist[target] = 0\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>smooth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-02-14</th>\n",
       "      <td>9.17</td>\n",
       "      <td>9.38</td>\n",
       "      <td>9.16</td>\n",
       "      <td>9.31</td>\n",
       "      <td>18700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.205647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-15</th>\n",
       "      <td>9.24</td>\n",
       "      <td>9.34</td>\n",
       "      <td>9.14</td>\n",
       "      <td>9.22</td>\n",
       "      <td>15700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.203333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-16</th>\n",
       "      <td>9.23</td>\n",
       "      <td>9.31</td>\n",
       "      <td>9.15</td>\n",
       "      <td>9.17</td>\n",
       "      <td>13800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.201019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-17</th>\n",
       "      <td>9.19</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.03</td>\n",
       "      <td>9.10</td>\n",
       "      <td>60800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.198705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-18</th>\n",
       "      <td>9.19</td>\n",
       "      <td>9.26</td>\n",
       "      <td>9.14</td>\n",
       "      <td>9.24</td>\n",
       "      <td>48300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.196392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-08</th>\n",
       "      <td>44.38</td>\n",
       "      <td>45.14</td>\n",
       "      <td>43.70</td>\n",
       "      <td>45.08</td>\n",
       "      <td>293600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.230497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-09</th>\n",
       "      <td>45.00</td>\n",
       "      <td>45.73</td>\n",
       "      <td>44.38</td>\n",
       "      <td>45.51</td>\n",
       "      <td>551400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.372137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-10</th>\n",
       "      <td>45.70</td>\n",
       "      <td>46.98</td>\n",
       "      <td>45.30</td>\n",
       "      <td>46.09</td>\n",
       "      <td>424600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.513778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-11</th>\n",
       "      <td>46.05</td>\n",
       "      <td>46.58</td>\n",
       "      <td>44.68</td>\n",
       "      <td>45.66</td>\n",
       "      <td>317500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.655419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-12</th>\n",
       "      <td>45.37</td>\n",
       "      <td>46.16</td>\n",
       "      <td>45.02</td>\n",
       "      <td>45.93</td>\n",
       "      <td>162300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.797060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2517 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close  Volume  Dividends  Stock Splits  \\\n",
       "2011-02-14   9.17   9.38   9.16   9.31   18700        0.0             0   \n",
       "2011-02-15   9.24   9.34   9.14   9.22   15700        0.0             0   \n",
       "2011-02-16   9.23   9.31   9.15   9.17   13800        0.0             0   \n",
       "2011-02-17   9.19   9.19   9.03   9.10   60800        0.0             0   \n",
       "2011-02-18   9.19   9.26   9.14   9.24   48300        0.0             0   \n",
       "...           ...    ...    ...    ...     ...        ...           ...   \n",
       "2021-02-08  44.38  45.14  43.70  45.08  293600        0.0             0   \n",
       "2021-02-09  45.00  45.73  44.38  45.51  551400        0.0             0   \n",
       "2021-02-10  45.70  46.98  45.30  46.09  424600        0.0             0   \n",
       "2021-02-11  46.05  46.58  44.68  45.66  317500        0.0             0   \n",
       "2021-02-12  45.37  46.16  45.02  45.93  162300        0.0             0   \n",
       "\n",
       "               smooth  \n",
       "2011-02-14   9.205647  \n",
       "2011-02-15   9.203333  \n",
       "2011-02-16   9.201019  \n",
       "2011-02-17   9.198705  \n",
       "2011-02-18   9.196392  \n",
       "...               ...  \n",
       "2021-02-08  44.230497  \n",
       "2021-02-09  44.372137  \n",
       "2021-02-10  44.513778  \n",
       "2021-02-11  44.655419  \n",
       "2021-02-12  44.797060  \n",
       "\n",
       "[2517 rows x 8 columns]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_orig = pd.read_csv('/Users/frkornet/CDA/Project/stockie/data/yfin_bak/ABCB.csv')\n",
    "hist_orig.index = hist_orig.Date.values\n",
    "del hist_orig['Date']\n",
    "hist_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(data, target):\n",
    "    \"\"\" \n",
    "    Given a standard yfinance data dataframe, add features that will help\n",
    "    the balanced scorecard to recognize buy and sell signals in the data.\n",
    "    The features are added as columns in the data dataframe. \n",
    "    \n",
    "    The original hist dataframe from yfinance is provided, so we can copy\n",
    "    the target to the data dataframe. The data dataframe with the extra \n",
    "    features is returned. The target argument contains the name of the \n",
    "    column that contains the the target.\n",
    "    \"\"\"\n",
    "    windows = [3, 5, 10, 15, 20, 30, 45, 60] \n",
    "\n",
    "    for i in windows:\n",
    "        ma = data.Close.rolling(i).mean()\n",
    "        # Moving Average Convergence Divergence (MACD)\n",
    "        data[f'MACD_{i}']    = ma - data.Close\n",
    "        data[f'PctDiff_{i}'] = data.Close.diff(i)\n",
    "        data[f'StdDev_{i}']  = data.Close.rolling(i).std()\n",
    "\n",
    "\n",
    "    exclude_cols = [target, 'smooth', 'Close', 'Date', 'Volume', 'Dividends', 'Stock Splits'] \n",
    "    factor = data.Close.copy()\n",
    "    for c in data.columns.tolist():\n",
    "        if c in exclude_cols:\n",
    "           continue\n",
    "        data[c] = data[c] / factor\n",
    "\n",
    "    for i in windows:\n",
    "        #data[f'RSI_{i}']     = RSI(data, i)\n",
    "        #data[f'WPR_{i}']     = WPR(data, i)\n",
    "        #data[f'MFI_{i}']     = MFI(data, i)\n",
    "        data[f'BBP_{i}']      = BBP(data, i)\n",
    "        \n",
    "    data = data.dropna()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSI_Frank(df, window):\n",
    "    price = hist['Close']\n",
    "    rsi = price.copy()\n",
    "    \n",
    "    daily_rets = price.copy()\n",
    "    daily_rets.values[1:] = price.values[1:] - price.values[:-1]\n",
    "    daily_rets.values[0]  = np.nan\n",
    "\n",
    "    up_rets = price.copy()\n",
    "    up_rets[:] = np.nan\n",
    "    up_rets[daily_rets >= 0] = daily_rets[daily_rets >= 0]\n",
    "    up_rets = up_rets.fillna(0).cumsum()\n",
    "    \n",
    "    down_rets = price.copy()\n",
    "    down_rets[:] = np.nan\n",
    "    down_rets[daily_rets <  0] = -daily_rets[daily_rets <  0] # .fillna(0).cumsum() * -1.0\n",
    "    down_rets = down_rets.fillna(0).cumsum() \n",
    "    \n",
    "    up_gain = price.copy()\n",
    "    up_gain[:window] = 0\n",
    "    up_gain.values[window:] = up_rets.values[window:] - up_rets.values[:-window]\n",
    "\n",
    "    down_loss = price.copy()\n",
    "    down_loss.iloc[:window] = 0 \n",
    "    down_loss.values[window:] = down_rets.values[window:] - down_rets.values[:-window]\n",
    "    \n",
    "    rs = (up_gain / window) / (down_loss / window)\n",
    "    \n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    rsi.iloc[:window] = np.nan\n",
    "\n",
    "    rsi[rsi == np.inf] == 100 \n",
    "    return rsi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSI_Harshad(df, window):\n",
    "    Gain=df['Close'].copy()\n",
    "    Loss=df['Close'].copy()\n",
    "    Avg_gain=df['Close'].copy()\n",
    "    Avg_loss=df['Close'].copy()\n",
    "    rsi=df['Close'].copy()\n",
    "\n",
    "    Gain[:]=0.0\n",
    "    Loss[:]=0.0\n",
    "    Avg_gain[:]=0.0\n",
    "    Avg_loss[:]=0.0\n",
    "    rsi[:]=np.nan\n",
    "\n",
    "    for i in range(1,len(df)):\n",
    "        if df.Close.iloc[i] > df.Close.iloc[i-1]:\n",
    "            Gain[i]=df.Close.iloc[i]-df.Close.iloc[i-1]\n",
    "        else:\n",
    "            # For loss save the absolute value on loss\n",
    "            Loss[i]=abs(df.Close.iloc[i]-df.Close.iloc[i-1])\n",
    "        if i>window:\n",
    "            Avg_gain[i]=(Avg_gain[i-1]*(window-1)+Gain[i])/window\n",
    "            Avg_loss[i]=(Avg_loss[i-1]*(window-1)+Loss[i])/window\n",
    "            rsi[i]=(100*Avg_gain[i]/(Avg_gain[i]+Avg_loss[i])).round(2)\n",
    "\n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSI(df, window):\n",
    "    return RSI_Frank(df, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WPR(df, window):\n",
    "\n",
    "    Highest_High = df['High'].rolling(window,min_periods=window).max()\n",
    "    Lowest_Low   = df['Low'].rolling(window,min_periods=window).min()\n",
    "    \n",
    "    denom = (Highest_High - Lowest_Low).values\n",
    "    denom[denom == 0] = 0.00001\n",
    "    wpr = 100 * (df['Close'] - Highest_High) / denom\n",
    "\n",
    "    return wpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFI(df, window):\n",
    "\n",
    "    typical_price = (df['High'] + df['Low'] + df['Close'])/3\n",
    "    raw_money_flow = typical_price*df['Volume']\n",
    "\n",
    "    idx = typical_price>typical_price.shift(1)\n",
    "\n",
    "    pos_money_flow = raw_money_flow.copy()\n",
    "    pos_money_flow.iloc[:] = 0.0\n",
    "    pos_money_flow.loc[idx] = raw_money_flow.loc[idx]\n",
    "\n",
    "    neg_money_flow = raw_money_flow.copy()\n",
    "    neg_money_flow.iloc[:] = 0.0\n",
    "    neg_money_flow.loc[~idx] = raw_money_flow.loc[~idx]\n",
    "\n",
    "    mfi_pos = pos_money_flow.rolling(window).sum()\n",
    "    mfi_neg = neg_money_flow.rolling(window).sum()\n",
    "    \n",
    "    denom = (mfi_pos+mfi_neg).values\n",
    "    denom[denom == 0] = 0.00001\n",
    "    mfi = 100 * mfi_pos / denom\n",
    "\n",
    "    return mfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BBP(df, window):   \n",
    "    MA=df['Close'].rolling(window).mean()\n",
    "    Std_Dev=df['Close'].rolling(window).std()\n",
    "\n",
    "    BOLU=MA+2*Std_Dev\n",
    "    BOLL=MA-2*Std_Dev\n",
    "\n",
    "    denom = (BOLU - BOLL).values\n",
    "    denom[denom == 0.0] = 0.00001\n",
    "    # bbp = ( df['Close'] - BOLL) / (BOLU - BOLL)\n",
    "    bbp = ( df['Close'] - BOLL) / denom\n",
    "    \n",
    "    return bbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-02-14         NaN\n",
       "2011-02-15         NaN\n",
       "2011-02-16    0.774559\n",
       "2011-02-17    0.773636\n",
       "2011-02-18    0.723174\n",
       "                ...   \n",
       "2021-02-08    0.738541\n",
       "2021-02-09    0.713317\n",
       "2021-02-10    0.767154\n",
       "2021-02-11    0.737727\n",
       "2021-02-12    0.645693\n",
       "Name: Close, Length: 2517, dtype: float64"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BBP(hist,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(a):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify(data):\n",
    "    \"\"\"\n",
    "    Convert a Pandas dataframe with numeric columns into a dataframe with only\n",
    "    columns of the data type string (in Pandas terminology an object). The \n",
    "    modified dataframe is returned. Note that the original dataframe is lost.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    for c in df.columns.tolist():\n",
    "        df[c] = df[c].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(stock_df, used_cols, target, train_pct):\n",
    "    \"\"\"\n",
    "    Split data set into a training and test data set:\n",
    "    - X contains the features for training and predicting. \n",
    "    - y contains the target for training and evaluating the performance.\n",
    "\n",
    "    Used_cols contain the features (i.e. columns) that you want to use\n",
    "    for training and prediction. Target contains the name of the column\n",
    "    that is the target.\n",
    "\n",
    "    Function returns X and y for cross validation, X and y for training, \n",
    "    and X and y for testing.\n",
    "    \"\"\"\n",
    "\n",
    "    test_starts_at = int(len(stock_df)*train_pct)\n",
    "    X = stock_df[used_cols]\n",
    "    y = stock_df[target]\n",
    "\n",
    "    X_train = stock_df[used_cols].iloc[:test_starts_at]\n",
    "    X_test  = stock_df[used_cols].iloc[test_starts_at:]\n",
    "    y_train = stock_df[target].iloc[:test_starts_at]\n",
    "    y_test  = stock_df[target].iloc[test_starts_at:]\n",
    "\n",
    "    return X, y, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signals(X_train, y_train, X_test, threshold):\n",
    "    \"\"\"\n",
    "    Used to predict buy and sell signals. The function itself has no awareness\n",
    "    what it is predicting. It is just a helper function used by \n",
    "    get_possible_trades().\n",
    "\n",
    "    Target is the column that contains the target. The other columns are\n",
    "    considered to be features to be used for training and prediction.\n",
    "\n",
    "    The function uses a balanced weight of evidence scorecard to predict the \n",
    "    signals. It returns the signals array.\n",
    "\n",
    "    Note that the function uses 70% for training and 30% for testing. The \n",
    "    date where the split happens is dependent on how much data the hist\n",
    "    dataframe contains. So, the caller will not see a single split date for\n",
    "    all tickers. \n",
    "    \"\"\"\n",
    "\n",
    "    scaler    = StandardScaler()\n",
    "    encoder   = WOEEncoder()\n",
    "    binner    = KBinsDiscretizer(n_bins=5, encode='ordinal')\n",
    "    objectify = FunctionTransformer(func=stringify, check_inverse=False, validate=False)\n",
    "    imputer   = SimpleImputer(strategy='constant', fill_value=0.0)\n",
    "    clf       = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "\n",
    "    pipe = make_pipeline(scaler, binner, objectify, encoder, imputer, clf)\n",
    "    pipe.fit(X_train, y_train.values)\n",
    "\n",
    "    test_signals = (pipe.predict_proba(X_test)  > threshold).astype(int)[:,1]\n",
    "    return y_train.values, test_signals.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_buy_n_sell_signals(buy_signals, sell_signals):\n",
    "    \"\"\"\n",
    "    The functions will take two lists and produce a single list containing the \n",
    "    buy and sell signals. The merged list will always start with a buy signal.\n",
    "    This is achieved by setting the state to SELL. That ensures that all sell \n",
    "    signals are quietly dropped until we get to the first buy signal.\n",
    "\n",
    "    Note: this function does not enforce that each buy signal is matched with  \n",
    "    a sell signal.\n",
    "\n",
    "    The function implements a simple deterministic state machine that flips \n",
    "    from SELL to BUY and back from BUY to SELL.\n",
    "\n",
    "    A buy in the merged list is 1 and a sell is 2. The merged list is\n",
    "    returned to the caller at the end.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(buy_signals) == len(sell_signals), \"buy_signal and sell_signal lengths different!\"\n",
    "    log(f'type(buy_signals) ={type(buy_signals)} len()={len(buy_signals)}')\n",
    "    log(f'type(sell_signals)={type(sell_signals)} len()={len(sell_signals)}')\n",
    "\n",
    "    buy_n_sell = np.zeros((len(buy_signals),), dtype=int)\n",
    "    length     = len(buy_n_sell)\n",
    "    i          = 0\n",
    "    state      = SELL\n",
    "\n",
    "    buy_ids  = np.where(buy_signals != 0)[0].tolist()\n",
    "    sell_ids = np.where(sell_signals != 0)[0].tolist()\n",
    "    log(f'merge_buy_n_sell_signals():')\n",
    "    log(f'- buy_ids ={buy_ids} len()={len(buy_ids)}')\n",
    "    log(f'- sell_ids={sell_ids} len()={len(sell_ids)}')\n",
    "    \n",
    "    while i < length:\n",
    "        if state == SELL and buy_signals[i] == 1:\n",
    "            state = BUY\n",
    "            buy_n_sell[i] = 1\n",
    "\n",
    "        elif state == BUY and sell_signals[i] == 1:\n",
    "            state = SELL\n",
    "            buy_n_sell[i] = 2\n",
    "            #continue\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "    buy_n_sell_ids  = np.where(buy_n_sell != 0)[0].tolist()\n",
    "    log(f'- buy_n_sell_ids ={buy_n_sell_ids} len()={len(buy_n_sell_ids)}')\n",
    "    return buy_n_sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_trades(hist, buy_n_sell, start_at, ticker, verbose):\n",
    "    #test_start_at = len(hist) - len(buy_n_sell)\n",
    "    log(f'extract_trades():')\n",
    "    log(f'- len(hist)={len(hist)}')\n",
    "    log(f'- len(buy_n_sell)={len(buy_n_sell)}')\n",
    "    log(f'- start_at={start_at}')\n",
    "    #test_start_at = 0\n",
    "\n",
    "    cols = ['buy_date', 'buy_close', 'sell_date', 'sell_close', 'gain_pct',\n",
    "            'trading_days', 'daily_return', 'ticker' ]\n",
    "    possible_trades_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    buy_id = sell_id = -1\n",
    "\n",
    "    for i, b_or_s in enumerate(buy_n_sell):\n",
    "\n",
    "        if b_or_s == BUY:\n",
    "            buy_id    = start_at + i\n",
    "            buy_close = hist.Close.iloc[buy_id]\n",
    "            buy_date  = hist.index[buy_id]\n",
    "\n",
    "        if b_or_s == SELL:\n",
    "            sell_id    = start_at + i\n",
    "            sell_close = hist.Close.iloc[sell_id]\n",
    "            sell_date  = hist.index[sell_id]\n",
    "\n",
    "            gain = sell_close - buy_close\n",
    "            gain_pct = round( (gain / buy_close)*100, 2)\n",
    "\n",
    "            trading_days = sell_id - buy_id\n",
    "\n",
    "            daily_return = (1+gain_pct/100) ** (1/trading_days) - 1\n",
    "            daily_return = round(daily_return * 100, 2)\n",
    "\n",
    "            trade_dict = {'buy_date'    : [buy_date],  'buy_close'    : [buy_close],\n",
    "                         'sell_date'    : [sell_date], 'sell_close'   : [sell_close],\n",
    "                         'gain_pct'     : [gain_pct],  'trading_days' : [trading_days],\n",
    "                         'daily_return' : [daily_return], 'ticker'    : [ticker] }\n",
    "            possible_trades_df = pd.concat([possible_trades_df,\n",
    "                                           pd.DataFrame(trade_dict)])\n",
    "    \n",
    "    if verbose == True:\n",
    "        log(\"****EXTRACT_TRADES****\")\n",
    "        log(possible_trades_df)\n",
    "\n",
    "    if buy_id > 0 and buy_id > sell_id:\n",
    "        buy_opportunity_df = {'ticker'    : [ticker] ,\n",
    "                              'buy_date'  : [buy_date],\n",
    "                              'buy_close' : [buy_close],\n",
    "                             }\n",
    "        buy_opportunity_df = pd.DataFrame(buy_opportunity_df)\n",
    "    else:\n",
    "        cols=['ticker', 'buy_date', 'buy_close']\n",
    "        buy_opportunity_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    return possible_trades_df, buy_opportunity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_buy_n_sell_signals(min_ids, max_ids):\n",
    "\n",
    "    length_i, length_j = len(min_ids), len(max_ids)\n",
    "    bns_pairs = []\n",
    "    i, j = 0, 0\n",
    "\n",
    "    while i < length_i and j < length_j:\n",
    "       # log(f'i={i} j={j} length_i={length_i} length_j={length_j} bns_pairs={bns_pairs}')\n",
    "       # log(f'min_ids[i]={min_ids[i]} max_ids[j]={max_ids[j]}')\n",
    "       if min_ids[i] >= max_ids[j]:\n",
    "          j += 1\n",
    "       else:\n",
    "          bns_pairs.append((min_ids[i], max_ids[j]))\n",
    "          i += 1\n",
    "          j += 1\n",
    "\n",
    "    return bns_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bns_pairs(hist, bns_pairs, verbose=False):\n",
    "\n",
    "    range_min, range_plus = -3, 3\n",
    "    min_ids, max_ids, drets = [], [], []\n",
    "    for (s,e) in bns_pairs:\n",
    "        if verbose: log(f's={s}, e={e}')\n",
    "        start_values = [s+i for i in range(range_min, range_plus+1)\n",
    "                        if s+i > 0 and s+i < len(hist)]\n",
    "        if verbose: log(f'start_values={start_values}')\n",
    "        end_values = [e+i for i in range(range_min, range_plus+1)\n",
    "                        if s+i > 0 and s+i < len(hist)]\n",
    "        if verbose: log(f'end_values={end_values}')\n",
    "\n",
    "        best_s = best_e = best_dret = None\n",
    "        for si in start_values:\n",
    "            for ei in end_values:\n",
    "                days = ei - si\n",
    "                if verbose: log(f\"- days={days}\")\n",
    "                if days < 5 or days > 50:\n",
    "                   continue\n",
    "\n",
    "                si_close = hist.Close.iloc[si]\n",
    "                ei_close = hist.Close.iloc[ei]\n",
    "                gain    = ei_close - si_close\n",
    "                if verbose: log(f\"- gain={gain}\")\n",
    "                if gain <= 0.0:\n",
    "                   continue\n",
    "\n",
    "                dret = (1 + gain/si_close) ** (1/days) - 1.0\n",
    "                if verbose: log(f\"- dret={dret}\")\n",
    "                if best_dret is None or dret > best_dret:\n",
    "                   best_s, best_e, best_dret = si, ei, dret\n",
    "                if verbose: log(f\"- best_s={best_s} best_e={best_e} best_dret={best_dret}\")\n",
    "\n",
    "        if best_dret is not None and best_dret >= 0.003:\n",
    "           if verbose: log(f\"adding {best_s}, {best_e}, {best_dret} to lists\")\n",
    "           min_ids.append(best_s)\n",
    "\n",
    "    log(f'process_bns_pairs(): min_ids={min_ids}')\n",
    "    log(f'process_bns_pairs(): max_ids={max_ids}')\n",
    "    log(f'process_bns_pairs(): drets={drets}')\n",
    "    return min_ids, max_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved smoothed price data for NTUS (len(hist)=2517, success=True)\n",
      "process_bns_pairs(): min_ids=[355, 409, 500, 599, 721, 776, 923, 984, 1207, 1282, 1395, 1437, 1491, 1557, 1639]\n",
      "process_bns_pairs(): max_ids=[]\n",
      "process_bns_pairs(): drets=[]\n",
      "- len(min_ids)      =21\n",
      "- len(max_ids)      =21\n",
      "- len(bns_pairs)    =20\n",
      "- bns_pairs         =[(152, 337), (352, 387), (406, 461), (497, 550), (596, 615), (650, 713), (718, 753), (773, 783), (822, 845), (851, 882), (920, 951), (983, 1032), (1095, 1180), (1206, 1236), (1283, 1323), (1392, 1412), (1438, 1487), (1489, 1536), (1556, 1582), (1638, 1650)]\n",
      "- len(new_min_ids)  =15\n",
      "- len(new_max_ids)  =0\n",
      "- min_ids           =[355, 409, 500, 599, 721, 776, 923, 984, 1207, 1282, 1395, 1437, 1491, 1557, 1639]\n",
      "- max_ids           =[]\n"
     ]
    }
   ],
   "source": [
    "ticker = 'NTUS'\n",
    "success, hist = get_stock_n_smooth(ticker, TRADE_PERIOD)\n",
    "if success == False:\n",
    "   assert 1 == 2, \"Error!\"\n",
    "\n",
    "secs = []\n",
    "\n",
    "# pre-process data, create features, and split data\n",
    "start_time = time()\n",
    "step = \"pre-process\"\n",
    "target = 'target'\n",
    "hist[target] = 0\n",
    "hist = features(hist, target)\n",
    "exclude_cols = [target, 'smooth', 'Close', 'Date', 'Volume', 'Dividends', 'Stock Splits']\n",
    "used_cols = [c for c in hist.columns.tolist() if c not in exclude_cols]\n",
    "X, y, X_train, X_test, y_train, y_test = split_data(hist, used_cols, target, 0.7)\n",
    "y_train_len = len(y_train)\n",
    "secs.append(time() - start_time)\n",
    "\n",
    "# pre-process data, create features, and split data\n",
    "start_time = time()\n",
    "step = \"local minima/maxima\"\n",
    "min_ids = argrelmin(hist.smooth.values)[0].tolist()\n",
    "max_ids = argrelmax(hist.smooth.values)[0].tolist()\n",
    "del hist['smooth']\n",
    "bns_pairs = pair_buy_n_sell_signals(min_ids, max_ids)\n",
    "new_min_ids, new_max_ids = process_bns_pairs(hist, bns_pairs)\n",
    "log(f\"- len(min_ids)      ={len(min_ids)}\")\n",
    "log(f\"- len(max_ids)      ={len(max_ids)}\")\n",
    "log(f\"- len(bns_pairs)    ={len(bns_pairs)}\")\n",
    "log(f\"- bns_pairs         ={bns_pairs}\")\n",
    "log(f\"- len(new_min_ids)  ={len(new_min_ids)}\")\n",
    "log(f\"- len(new_max_ids)  ={len(new_max_ids)}\")\n",
    "min_ids, max_ids = new_min_ids, new_max_ids\n",
    "log(f\"- min_ids           ={min_ids}\")\n",
    "log(f\"- max_ids           ={max_ids}\")\n",
    "secs.append(time() - start_time)\n",
    "\n",
    "# get the buy signals\n",
    "start_time = time()\n",
    "step = \"get buy signals\"\n",
    "hist[target] = 0\n",
    "hist[target].iloc[min_ids] = 1\n",
    "y_train = hist[target].iloc[0:y_train_len].copy()\n",
    "#train_buy_signals, test_buy_signals = \\\n",
    "#    get_signals(X_train, y_train, X_test, BUY_THRESHOLD)\n",
    "# test_buy_signals += len(train_buy_signals)\n",
    "#secs.append(time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler    = StandardScaler()\n",
    "encoder   = WOEEncoder()\n",
    "binner    = KBinsDiscretizer(n_bins=5, encode='ordinal')\n",
    "objectify = FunctionTransformer(func=stringify, check_inverse=False, validate=False)\n",
    "imputer   = SimpleImputer(strategy='constant', fill_value=0.0)\n",
    "clf       = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "\n",
    "# pipe = make_pipeline(scaler, binner, objectify, encoder, imputer, clf)\n",
    "pipe = make_pipeline(scaler, binner, objectify, encoder, imputer, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013-09-30    0\n",
       "2013-10-01    0\n",
       "2013-10-02    0\n",
       "2013-10-03    0\n",
       "2013-10-04    0\n",
       "             ..\n",
       "2018-11-16    0\n",
       "2018-11-19    0\n",
       "2018-11-20    0\n",
       "2018-11-21    0\n",
       "2018-11-23    0\n",
       "Name: target, Length: 1299, dtype: int64"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('kbinsdiscretizer', KBinsDiscretizer(encode='ordinal')),\n",
       "                ('functiontransformer',\n",
       "                 FunctionTransformer(check_inverse=False,\n",
       "                                     func=<function stringify at 0x7fb211edec20>)),\n",
       "                ('woeencoder',\n",
       "                 WOEEncoder(cols=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n",
       "                                  14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
       "                                  25, 26, 27, 28, 29, ...])),\n",
       "                ('simpleimputer',\n",
       "                 SimpleImputer(fill_value=0.0, strategy='constant')),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(class_weight='balanced', random_state=42))])"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open          1299\n",
       "High          1299\n",
       "Low           1299\n",
       "P/E Ratio     1299\n",
       "MACD_3        1299\n",
       "PctDiff_3     1299\n",
       "StdDev_3      1299\n",
       "MACD_5        1299\n",
       "PctDiff_5     1299\n",
       "StdDev_5      1299\n",
       "MACD_10       1299\n",
       "PctDiff_10    1299\n",
       "StdDev_10     1299\n",
       "MACD_15       1299\n",
       "PctDiff_15    1299\n",
       "StdDev_15     1299\n",
       "MACD_20       1299\n",
       "PctDiff_20    1299\n",
       "StdDev_20     1299\n",
       "MACD_30       1299\n",
       "PctDiff_30    1299\n",
       "StdDev_30     1299\n",
       "MACD_45       1299\n",
       "PctDiff_45    1299\n",
       "StdDev_45     1299\n",
       "MACD_60       1299\n",
       "PctDiff_60    1299\n",
       "StdDev_60     1299\n",
       "BBP_3         1299\n",
       "BBP_5         1299\n",
       "BBP_10        1299\n",
       "BBP_15        1299\n",
       "BBP_20        1299\n",
       "BBP_30        1299\n",
       "BBP_45        1299\n",
       "BBP_60        1299\n",
       "dtype: int64"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isfinite(X_train)) # == 1719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-06-30    0.628931\n",
       "2011-07-01    0.628931\n",
       "2011-07-05    0.628931\n",
       "2011-07-06    0.628931\n",
       "2011-07-07    0.628931\n",
       "                ...   \n",
       "2021-02-08   -0.546448\n",
       "2021-02-09   -0.546448\n",
       "2021-02-10   -0.546448\n",
       "2021-02-11   -0.546448\n",
       "2021-02-12   -0.546448\n",
       "Name: P/E Ratio, Length: 2422, dtype: float64"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['P/E Ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('learn': conda)",
   "language": "python",
   "name": "python37564bitlearnconda9edf13e24aea43b294d817638a3bc50f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
